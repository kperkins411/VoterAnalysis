{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Voter Analysis exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.tabular import *\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 60\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# Visualizations\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='white')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the data\n",
    "path = './data/'\n",
    "df = pd.read_csv('./data/ccesplus.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of spaces and caps in column names (if any)\n",
    "df.columns = [col.replace(' ','_').lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()\n",
    "\n",
    "# df.columns\n",
    "\n",
    "# df.describe()\n",
    "\n",
    "#any duplicate rows?\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns=866\n",
      "Total columns with no Nans= 268\n",
      "Total columns with Nans= 598\n"
     ]
    }
   ],
   "source": [
    "#lets see how many columns, how many have no and some missing values\n",
    "print (f\"Total columns={len(df.columns)}\")\n",
    "print(f\"Total columns with no Nans= {len(df.columns[~df.isnull().any()])}\") \n",
    "print(f\"Total columns with Nans= {len(df.columns[df.isnull().any()])}\") #add ~ to get columns with no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns with no NaNs (missing values) are the easiest to use since we dont have to impute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a subset of the rows of the data to work on if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first thousand rows\n",
    "# df=df[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See what the summary columns do\n",
    "looks like the summaries (..sum) are just the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc.cc16_422c</th>\n",
       "      <th>cc.cc16_422d</th>\n",
       "      <th>cc.cc16_422e</th>\n",
       "      <th>cc.cc16_422f</th>\n",
       "      <th>cc.raceviewsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cc.cc16_422c  cc.cc16_422d  cc.cc16_422e  cc.cc16_422f  cc.raceviewsum\n",
       "0           1.0           2.0           2.0           2.0            1.75\n",
       "1           1.0           3.0           1.0           2.0            1.75\n",
       "2           NaN           NaN           NaN           NaN             NaN\n",
       "3           NaN           NaN           NaN           NaN             NaN\n",
       "4           1.0           1.0           1.0           1.0            1.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['cc.CC16_422c','cc.CC16_422d','cc.CC16_422e','cc.CC16_422f', 'cc.raceviewsum']\n",
    "columns = [col.lower() for col in columns]\n",
    "tmp_df=df[columns]\n",
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains all the columns that original logits were run on\n",
    "#use these to start to compare neural network solution\n",
    "columns = pd.read_excel('./data/results cces.xlsx',encoding = \"ISO-8859-1\", skiprows=3)\n",
    "columns = list(columns.iloc[:,0])\n",
    "\n",
    "#get the dependant variable(s)\n",
    "# columns_dep_var= ['cc.TrumpGEVote','cc.TrumpPVote', 'cc.vote12.gop']\n",
    "columns_dep_var= ['cc.trumpgevote']\n",
    "\n",
    "#combine\n",
    "columns.extend(columns_dep_var)\n",
    "\n",
    "#strip rubbish\n",
    "columns = [col.replace(' ','_').lower() for col in columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select out the columns of interest\n",
    "df_s=df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_s.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc.blackdum:2\n",
      "econ.mhi:2646\n",
      "cc.sex:2\n",
      "cc.maxeduc.4yr:2\n",
      "econ.hhpov.p:1030\n",
      "mort.ucd.despair.disc95.pdpy:2660\n",
      "cc.union:2\n",
      "cc.age:80\n",
      "demo.popdense:2668\n",
      "cc.emp.nojob:2\n",
      "rustpc:2437\n",
      "taa.wrks.disc95.pcpy:2120\n",
      "cc.faminc:16\n",
      "crashpc:2626\n",
      "cc.newsint:5\n",
      "cc.isimmigrant:2\n",
      "cc.catholic:2\n",
      "cc.cc16_305_2:2\n",
      "job.uer:761\n",
      "cc.child18:2\n",
      "cc.evanprot:2\n",
      "cc.whitedum:2\n",
      "cc.religiosity:15\n",
      "cc.cc16_351b:2\n",
      "cc.cc16_307:4\n",
      "cc.immviewsum:5\n",
      "cc.cc16_304:5\n",
      "cc.inddum:2\n",
      "cc.ideo7:7\n",
      "cc.raceviewsum:17\n",
      "cc.repdum:2\n",
      "cc.trumpgevote:2\n"
     ]
    }
   ],
   "source": [
    "# how many unique values there are per column, \n",
    "# use that to guide which columns are categorical and which are continuous\n",
    "#pick largest value that looks continuous, for instance raceviewsum=17 \n",
    "#(but see the docs many of theses fields are floats which meand fastai ignores cardinality)\n",
    "for col in df_s.columns:\n",
    "    print(f\"{col}:{df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cc.blackdum                       int64\n",
       "econ.mhi                        float64\n",
       "cc.sex                            int64\n",
       "cc.maxeduc.4yr                    int64\n",
       "econ.hhpov.p                    float64\n",
       "mort.ucd.despair.disc95.pdpy    float64\n",
       "cc.union                        float64\n",
       "cc.age                            int64\n",
       "demo.popdense                   float64\n",
       "cc.emp.nojob                      int64\n",
       "rustpc                          float64\n",
       "taa.wrks.disc95.pcpy            float64\n",
       "cc.faminc                       float64\n",
       "crashpc                         float64\n",
       "cc.newsint                      float64\n",
       "cc.isimmigrant                    int64\n",
       "cc.catholic                     float64\n",
       "cc.cc16_305_2                     int64\n",
       "job.uer                         float64\n",
       "cc.child18                      float64\n",
       "cc.evanprot                     float64\n",
       "cc.whitedum                       int64\n",
       "cc.religiosity                  float64\n",
       "cc.cc16_351b                    float64\n",
       "cc.cc16_307                     float64\n",
       "cc.immviewsum                   float64\n",
       "cc.cc16_304                     float64\n",
       "cc.inddum                       float64\n",
       "cc.ideo7                        float64\n",
       "cc.raceviewsum                  float64\n",
       "cc.repdum                       float64\n",
       "cc.trumpgevote                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what types are the columns\n",
    "df_s.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cc.blackdum                     0.000000\n",
       "cc.immviewsum                   0.000000\n",
       "cc.whitedum                     0.000000\n",
       "cc.cc16_305_2                   0.000000\n",
       "cc.emp.nojob                    0.000000\n",
       "cc.age                          0.000000\n",
       "cc.isimmigrant                  0.000000\n",
       "cc.sex                          0.000000\n",
       "cc.maxeduc.4yr                  0.000000\n",
       "cc.evanprot                     0.000666\n",
       "cc.newsint                      0.000820\n",
       "cc.catholic                     0.001130\n",
       "demo.popdense                   0.001300\n",
       "econ.hhpov.p                    0.001300\n",
       "econ.mhi                        0.001300\n",
       "taa.wrks.disc95.pcpy            0.001300\n",
       "job.uer                         0.001300\n",
       "cc.cc16_307                     0.001517\n",
       "mort.ucd.despair.disc95.pdpy    0.001548\n",
       "cc.child18                      0.001827\n",
       "cc.cc16_351b                    0.001950\n",
       "cc.cc16_304                     0.002059\n",
       "cc.union                        0.002136\n",
       "crashpc                         0.002229\n",
       "rustpc                          0.002229\n",
       "cc.religiosity                  0.031084\n",
       "cc.ideo7                        0.057817\n",
       "cc.repdum                       0.058854\n",
       "cc.inddum                       0.058854\n",
       "cc.faminc                       0.103452\n",
       "cc.raceviewsum                  0.186703\n",
       "cc.trumpgevote                  0.367028\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the percentage of NaNs in each column, note the large percentage of missing values in the bottom columns\n",
    "#I would guess that cc.faminc and cc.raceviewsum are critical\n",
    "df_s.isna().sum().sort_values(ascending = True)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BUMMER! the dependant variable has a lot of missing values (36.7%)\n",
    "df_s['cc.trumpgevote'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN dependent variable rows\n",
    "whaddaya going to do?  You have no way of knowing how these people voted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64600 rows in df_s\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(df_s)} rows in df_s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the NaN rows\n",
    "df_s = df_s[pd.notnull(df_s['cc.trumpgevote'] )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    22136\n",
       "1.0    18754\n",
       "Name: cc.trumpgevote, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#is the dataset balanced?\n",
    "df_s['cc.trumpgevote'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out categorical and continuous variables\n",
    "see if fastai can auto do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#give fastai a shot at splitting cat and cont variables\n",
    "res_cont, res_cat = cont_cat_split(df_s,max_card=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['econ.mhi', 'econ.hhpov.p', 'mort.ucd.despair.disc95.pdpy', 'cc.union', 'cc.age', 'demo.popdense', 'rustpc', 'taa.wrks.disc95.pcpy', 'cc.faminc', 'crashpc', 'cc.newsint', 'cc.catholic', 'job.uer', 'cc.child18', 'cc.evanprot', 'cc.religiosity', 'cc.cc16_351b', 'cc.cc16_307', 'cc.immviewsum', 'cc.cc16_304', 'cc.inddum', 'cc.ideo7', 'cc.raceviewsum', 'cc.repdum', 'cc.trumpgevote']\n",
      "['cc.blackdum', 'cc.sex', 'cc.maxeduc.4yr', 'cc.emp.nojob', 'cc.isimmigrant', 'cc.cc16_305_2', 'cc.whitedum']\n"
     ]
    }
   ],
   "source": [
    "print(res_cont)\n",
    "print(res_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the dependant variable\n",
    "res_cont = [x for x in res_cont if x not in columns_dep_var]\n",
    "res_cat = [x for x in res_cat if x not in columns_dep_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert trumpgevote to long (otherwise fit fails)\n",
    "df_s['cc.trumpgevote'] = df_s['cc.trumpgevote'].astype('int64');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36801\n",
      "4089\n"
     ]
    }
   ],
   "source": [
    "# split out data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train,val_test = train_test_split(df_s, test_size=0.2)\n",
    "# val, test = train_test_split(val_test, test_size=0.5)\n",
    "# print(str(len(train)))\n",
    "# print(str(len(val)))\n",
    "# print(str(len(test)))   \n",
    "train,test = train_test_split(df_s, test_size=0.1)\n",
    "print(str(len(train)))\n",
    "# print(str(len(val)))\n",
    "print(str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TabularList.from_df(test,  cat_names=res_cat, cont_names=res_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all this to get a random list of validation indexes\n",
    "from numpy import random\n",
    "\n",
    "#generate a list of all indexes\n",
    "i = list(range(len(train)))\n",
    "\n",
    "#shuffle it\n",
    "random.shuffle(i)\n",
    "\n",
    "#get number of indexes corresponding to val percentage\n",
    "number = int(len(i)*.1)\n",
    "\n",
    "#select validation indexes\n",
    "val_idx=i[:number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df_s,  cat_names=res_cat, cont_names=res_cont, procs=procs)\n",
    "                           .split_by_idx(val_idx)\n",
    "                           .label_from_df(cols=columns_dep_var)\n",
    "                           .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.show_batch(rows=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a learner\n",
    "learn = tabular_learner(data, layers=[200,100], metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:20 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209166</td>\n",
       "      <td>0.228213</td>\n",
       "      <td>0.916576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217473</td>\n",
       "      <td>0.219228</td>\n",
       "      <td>0.912228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206864</td>\n",
       "      <td>0.221938</td>\n",
       "      <td>0.909783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206027</td>\n",
       "      <td>0.213631</td>\n",
       "      <td>0.920109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.202527</td>\n",
       "      <td>0.221812</td>\n",
       "      <td>0.912772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(epochs=5, lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, targets = learn.get_preds(test)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37210"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37210"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)\n",
    "len(targets)\n",
    "\n",
    "type(targets)\n",
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find index of largest output\n",
    "preds=[torch.argmax(x).item() for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Test dataset accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9134641225477023\n"
     ]
    }
   ],
   "source": [
    "totals = len(preds)\n",
    "matches = 0\n",
    "for x in zip(preds,targets):\n",
    "    if x[0]==x[1]:\n",
    "        matches+=1\n",
    "print(f\"Accuracy is {matches/totals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Show graphs and stats here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "This model is 92% accurate with no data tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
