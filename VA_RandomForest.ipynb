{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is the random forest learner associated with Voter Analysis.\n",
    "Please be sure to run DataCleaning.ipynb first to prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.tabular import *\n",
    "from fastai import *\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 60\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# Visualizations\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='white')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load df_s and catagorical and continuous column names\n",
    "If either of the following fail then please be sure to run DataCleaning.ipynb first to prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = pd.read_feather('tmp/df_s')\n",
    "# df_s.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/catcont.json') as f:\n",
    "    data1 = json.load(f)\n",
    "    res_cont = data1[0]\n",
    "    res_cat = data1[1] \n",
    "    columns_dep_var = data1[2][0]\n",
    "    \n",
    "# res_cont\n",
    "# res_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.trumpgevote'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dep_var = data1[2][0]\n",
    "columns_dep_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorify and Fill Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from docs https://docs.fast.ai/tabular.transform.html\n",
    "tfm = Categorify(cat_names=res_cat, cont_names=res_cont)\n",
    "tfm(df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1], dtype='int64')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just checking to see if it works on any old variable\n",
    "df_s[res_cat[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm1 = FillMissing(cat_names=res_cat, cont_names=res_cont)\n",
    "tfm1(df_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36801\n",
      "4089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40890"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split out data\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "trn,tst = train_test_split(df_s, test_size=0.1)\n",
    "print(str(len(trn)))\n",
    "print(str(len(tst)))\n",
    "\n",
    "len(df_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n",
    "#create a random forest object\n",
    "m_rf = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y=trn[columns_dep_var].copy()\n",
    "trn=trn.drop(columns_dep_var,axis=1)\n",
    "\n",
    "tst_y=tst[columns_dep_var].copy()\n",
    "tst=tst.drop(columns_dep_var,axis=1)\n",
    "\n",
    "# trn.T\n",
    "# trn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trn columns = 53, total tst columns = 53\n",
      "Total trn columns with Nans= 0\n",
      "Total tst columns with Nans= 0\n"
     ]
    }
   ],
   "source": [
    "#You cannot have any Nan (missing data) fields or random forest will not work.\n",
    "print(f\"Total trn columns = {len(trn.columns)}, total tst columns = {len(tst.columns)}\") \n",
    "print(f\"Total trn columns with Nans= {len(trn.columns[trn.isnull().any()])}\") #add ~ to get columns with no missing values\n",
    "print(f\"Total tst columns with Nans= {len(tst.columns[tst.isnull().any()])}\") #add ~ to get columns with no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hmmm if tst has 1 more column than train then see what it is\n",
    "set(tst.columns)-set(trn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the random forest \n",
    "m_rf.fit(trn, trn_y)\n",
    "\n",
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(trn), trn_y), rmse(m.predict(tst), tst_y),\n",
    "                m.score(trn, trn_y), m.score(tst, tst_y)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9610694979455728"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how good is it? R**2 => 1 means perfect, 0 means always predicts the mean, - value less than 1/2 right \n",
    "m_rf.score(trn,trn_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09830229574847503, 0.24587884706615393, 0.9610694979455728, 0.7570594976612659, 0.7205749887677839]\n"
     ]
    }
   ],
   "source": [
    "print_score(m_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get a correct list of all the test labels\n",
    "targets = [int(item['cc.trumpgevote']) for item in test_long]\n",
    "# targets1 = [int(item[31]) for item in test_long]\n",
    "# print(f\"targets length={len(targets)}, targets1 length={len(targets1)}\")\n",
    "# print(f\"Matches in targets and targets1={len([1 for i,x in zip(targets,targets1) if i==x])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(preds,targs):\n",
    "    totals = len(preds)\n",
    "    matches = 0\n",
    "    for x in zip(preds,targs):\n",
    "        if x[0]==x[1]:\n",
    "            matches+=1\n",
    "    print(f\"Got {matches} right out of {totals} samples, Accuracy is {matches/totals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The long, very slow way.  One at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it the hard way one at a time\n",
    "preds1=[]\n",
    "# for item in test_long[:100]:\n",
    "for item in test_long:\n",
    "    _,pred, _ = learn.predict(item)\n",
    "    preds1.append(pred.item())\n",
    "# len(preds1)\n",
    "# preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy(preds1,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The easy, fast batched way\n",
    "However note that get_preds does not return the labels as its second param as it indicates in documentation, bug in FastaAI?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING THE FOLLOWING CALL, get_preds DOES NOT RETURN CORRECT LABELS AS DOCS IMPLY\n",
    "predictions, _ = learn.get_preds(DatasetType.Test)\n",
    "\n",
    "# type(predictions)\n",
    "# predictions.tolist()[:10]\n",
    "#targets.tolist()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find index of largest output\n",
    "preds=[torch.argmax(x).item() for x in predictions]\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy(preds,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the same size?\n",
    "len(test_vec)\n",
    "len(test_long)\n",
    "len(preds)\n",
    "len(preds1)\n",
    "len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check outputs of both methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Targets same values are ={len([1 for x,y in zip(targets,targets1) if x==y])}\")\n",
    "print(f\"Predictions same values are ={len([1 for x,y in zip(preds,preds1) if x==y])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from fastai.callbacks.hooks import *\n",
    "print(model_summary(learn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Show graphs and stats here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "This model is 92% accurate with no data tweaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test[0]\n",
    "data[31]\n",
    "type(data)\n",
    "data.shape\n",
    "tmp=learn.predict(data)\n",
    "len(tmp)\n",
    "out,pred,res=tmp\n",
    "\n",
    "out\n",
    "pred\n",
    "res\n",
    "\n",
    "# len(out)\n",
    "# len(pred)\n",
    "len(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "472px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "341px",
    "left": "55px",
    "right": "20px",
    "top": "419px",
    "width": "408px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
