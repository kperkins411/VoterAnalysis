{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is the Marginal Effects at Means portion of the project\n",
    "Please be sure to run DataCleaning.ipynb first to prepare the data\n",
    "\n",
    "This notebook based on Fastai V1 ML course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.tabular import *\n",
    "from fastai import *\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 60\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# Visualizations\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETERMINE IF YOU ARE USING RAW OR SCALED\n",
    "Scaled is Zhao's data, continuous variables divided by standard deviation\n",
    "<br>Raw is unscaled raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "useSavedModel=True\n",
    "filename_model_params = \"RF_model_params.sav\"\n",
    "useRaw=False\n",
    "outdir = 'outBElectionResultsScaled2'\n",
    "filename='results.csv'\n",
    "filename_all = 'results_complete.csv'\n",
    "filename_model_params = \"RF_model_params.sav\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# the dependant variable(s)\n",
    "columns_dep_var= ['cc.TrumpGEVote','cc.TrumpPVote', 'cc.vote12.gop']\n",
    "\n",
    "#get the data\n",
    "if (useRaw == True):\n",
    "    df = pd.read_csv('./data/ccesplus.csv',encoding = \"ISO-8859-1\")\n",
    "else:\n",
    "    df = pd.read_csv('./data/ccesplus_fscaled.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the columns of interest, including all dependent vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.read_excel('./data/CCESplusVariables.xlsx',encoding = \"ISO-8859-1\")\n",
    "\n",
    "# for every regid=3.1 get the third column (variable name) convert to a list\n",
    "columns = list(all[ (all['regid']==1.1) & (all['exclude']!='t')  ].iloc[:,2])\n",
    "\n",
    "# #strip dependant variables\n",
    "# columns = [col for col in columns if col not in columns_dep_var]\n",
    "# columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING! 'cc.i.white.educhs not in df! No worries though \n",
    "#its correlated with composed of cc.maxeduc.hs and cc.WhiteDum\n",
    "#so drop it\n",
    "columns.remove('cc.i.white.educhs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)\n",
    "# columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract just those columns from orig dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which dependant variable to operate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = columns_dep_var[0]\n",
    "dump_these_dep_var_columns=columns_dep_var.copy()\n",
    "dump_these_dep_var_columns.remove(dep_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN dependent variable rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 23710 rows where cc.TrumpGEVote=NaN\n"
     ]
    }
   ],
   "source": [
    "def remove_dep_var_nan_rows(df, col_dep_var, dump_these_dep_var_columns ,silent = False):\n",
    "    \"\"\"\n",
    "    parse df into rows where df.col_dep_var does not have NaNs, \n",
    "    df: dataframe to pull NaN rows out of\n",
    "    col_dep_var: dependent variable\n",
    "    dump_these_dep_var_columns: other dep_var columns that may be highly correlated with dep var\n",
    "    \"\"\"\n",
    "    dftmp= df.copy()\n",
    "    \n",
    "    if(silent is False):\n",
    "        print(f'dropping {(pd.isnull(dftmp[col_dep_var])).sum()} rows where {col_dep_var}=NaN')\n",
    "                      \n",
    "    #dump the NaN rows\n",
    "    dftmp = dftmp[pd.notnull(dftmp[col_dep_var] )]\n",
    "    \n",
    "    #dump the dump_these_dep_var_columns\n",
    "    dftmp.drop(dump_these_dep_var_columns,axis=1,inplace=True);\n",
    "    \n",
    "    return dftmp\n",
    "\n",
    "# pull out the nulls from the column of interest\n",
    "dftmp= remove_dep_var_nan_rows(df, columns_dep_var[0],dump_these_dep_var_columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cc.emp.nojob', 'cc.CC16_304', 'cc.faminc', 'crashpc', 'rustpc',\n",
       "       'job.uer', 'econ.mhi', 'econ.hhpov.p', 'taa.wrks.disc95.pcpy',\n",
       "       'cc.CC16_305_2', 'mort.ucd.despair.disc95.pdpy', 'cc.immviewsum',\n",
       "       'cc.raceviewsum', 'cc.CC16_307', 'cc.CC16_351B', 'cc.Age', 'cc.Sex',\n",
       "       'cc.BlackDum', 'cc.WhiteDum', 'cc.maxeduc.4yr', 'cc.maxeduc.hs',\n",
       "       'cc.isimmigrant', 'cc.child18', 'cc.union', 'cc.newsint', 'cc.Ideo7',\n",
       "       'cc.EvanProt', 'cc.Catholic', 'cc.Religiosity', 'demo.popdense',\n",
       "       'cc.RepDum', 'cc.IndDum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a list of the columns to operate on minus the dependant variable\n",
    "columns = dftmp.columns.drop(dep_var)\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out categorical and continuous variables\n",
    "see if fastai can auto do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #give fastai a shot at splitting cat and cont variables\n",
    "res_cont, res_cat = cont_cat_split(dftmp,max_card=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorify and Fill Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from docs https://docs.fast.ai/tabular.transform.html\n",
    "# tfm = Categorify(cat_names=res_cat, cont_names=res_cont)\n",
    "# tfm(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm1 = FillMissing(cat_names=res_cat, cont_names=res_cont, add_col=False)\n",
    "tfm1(dftmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36801\n",
      "4089\n"
     ]
    }
   ],
   "source": [
    "# split out train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trn=tst=None\n",
    "trn,tst = train_test_split(dftmp, test_size=0.1)\n",
    "print(str(len(trn)))\n",
    "print(str(len(tst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split out trn_y and tst_y\n",
    "#this is the dep_var, converted to an int\n",
    "trn_y = trn[dep_var].copy()\n",
    "tst_y = tst[dep_var].copy()\n",
    "trn_y.astype('int64');\n",
    "trn_y.astype('int64');\n",
    "\n",
    "trn.drop(dep_var,axis=1,inplace=True);\n",
    "tst.drop(dep_var,axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the standard deviation for every column of interest\n",
    "For continuous variables we need to subtract 1 standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a RandomForest on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "if (useSavedModel):\n",
    "    # load the model from disk\n",
    "    m_rf = pickle.load(open(outdir+\"/\"+filename_model_params, 'rb'))\n",
    "else:\n",
    "    #create a random forest object\n",
    "    m_rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, oob_score=True, max_features='auto', min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmse(x,y): \n",
    "    '''this and R**2 used for continuous variables'''\n",
    "    return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m, trn, trn_y, tst, tst_y):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    res = [m.score(trn, trn_y), m.score(tst, tst_y)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)\n",
    "\n",
    "def eval_accuracy(preds,targs, silent=True):\n",
    "    totals = len(preds)\n",
    "    matches = 0\n",
    "    for x in zip(preds,targs):\n",
    "        if x[0]==x[1]:\n",
    "            matches+=1\n",
    "    acc=100*matches/totals \n",
    "    if( silent == False):\n",
    "        print(f\"Got {matches} right out of {totals} samples, Accuracy is {acc} percent\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=999, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9388603570555148, 0.9107361213010516, 0.9160892367055243]\n"
     ]
    }
   ],
   "source": [
    "#train the random forest \n",
    "m_rf.fit(trn, trn_y)\n",
    "print_score(m_rf, trn, trn_y, tst, tst_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just another way to see stuff\n",
    "# preds1 = m_rf.predict(tst)\n",
    "# eval_accuracy(preds1,tst_y,silent=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cc.emp.nojob', 'cc.CC16_304', 'cc.faminc', 'crashpc', 'rustpc',\n",
       "       'job.uer', 'econ.mhi', 'econ.hhpov.p', 'taa.wrks.disc95.pcpy',\n",
       "       'cc.CC16_305_2', 'mort.ucd.despair.disc95.pdpy', 'cc.immviewsum',\n",
       "       'cc.raceviewsum', 'cc.CC16_307', 'cc.CC16_351B', 'cc.Age', 'cc.Sex',\n",
       "       'cc.BlackDum', 'cc.WhiteDum', 'cc.maxeduc.4yr', 'cc.maxeduc.hs',\n",
       "       'cc.isimmigrant', 'cc.child18', 'cc.union', 'cc.newsint', 'cc.Ideo7',\n",
       "       'cc.EvanProt', 'cc.Catholic', 'cc.Religiosity', 'demo.popdense',\n",
       "       'cc.RepDum', 'cc.IndDum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run MEMs on columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this directory contains symlink created at command line like this\n",
    "# ln -s ../Marginal_Effects_at_Means ./Marginal_Effects_at_Means\n",
    "#it allows this directory to find Marginal_Effects_at_Means, a directory 1 above this one\n",
    "#this dir contains a file called mem.py which contains MEMs\n",
    "from Marginal_Effects_at_Means.mem import MEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = trn.copy().append(tst.copy(), ignore_index=True)\n",
    "all_y = trn_y.copy().append(tst_y.copy(), ignore_index=True)\n",
    "len(all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc.emp.nojob    2\n",
      "cc.CC16_304    5\n",
      "cc.faminc    16\n",
      "crashpc    2439\n",
      "rustpc    2264\n",
      "job.uer    741\n",
      "econ.mhi    2456\n",
      "econ.hhpov.p    1000\n",
      "taa.wrks.disc95.pcpy    2013\n",
      "cc.CC16_305_2    2\n",
      "mort.ucd.despair.disc95.pdpy    2466\n",
      "cc.immviewsum    5\n",
      "cc.raceviewsum    17\n",
      "cc.CC16_307    4\n",
      "cc.CC16_351B    2\n",
      "cc.Age    78\n",
      "cc.Sex    2\n",
      "cc.BlackDum    2\n",
      "cc.WhiteDum    2\n",
      "cc.maxeduc.4yr    2\n",
      "cc.maxeduc.hs    2\n",
      "cc.isimmigrant    2\n",
      "cc.child18    2\n",
      "cc.union    2\n",
      "cc.newsint    5\n",
      "cc.Ideo7    7\n",
      "cc.EvanProt    2\n",
      "cc.Catholic    2\n",
      "cc.Religiosity    15\n",
      "demo.popdense    2473\n",
      "cc.RepDum    2\n",
      "cc.IndDum    2\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "# all.dtypes\n",
    "for val in all.columns:\n",
    "    if (is_numeric_dtype(all[val])):\n",
    "        print(f\"{val}    {all[val].nunique()}\")\n",
    "#     if all[val].dtype == 'float':\n",
    "#          print(f\"{val}    {all[val].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5799542961462802"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9396806189703275"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "count    40890.000000\n",
       "mean         0.939681\n",
       "std          0.297727\n",
       "min          0.315991\n",
       "25%          0.631982\n",
       "50%          0.947973\n",
       "75%          0.947973\n",
       "max          1.579954\n",
       "Name: cc.CC16_304, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all['cc.CC16_304'].max()\n",
    "all['cc.CC16_304'].mean()\n",
    "all['cc.CC16_304'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ON WHOLE DATASET OR JUST THE TestSET?  I'm thinking the whole dataset.  \n",
    "# The model has some idea of how voters will vote based on the input features, lets use that knowledge\n",
    "#to see what happens when we start changing variables\n",
    "mems = MEMs(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cc.TrumpGEVote                  float64\n",
       "cc.emp.nojob                      int64\n",
       "cc.CC16_304                     float64\n",
       "cc.faminc                       float64\n",
       "crashpc                         float64\n",
       "rustpc                          float64\n",
       "job.uer                         float64\n",
       "econ.mhi                        float64\n",
       "econ.hhpov.p                    float64\n",
       "taa.wrks.disc95.pcpy            float64\n",
       "cc.CC16_305_2                     int64\n",
       "mort.ucd.despair.disc95.pdpy    float64\n",
       "cc.immviewsum                   float64\n",
       "cc.raceviewsum                  float64\n",
       "cc.CC16_307                     float64\n",
       "cc.CC16_351B                    float64\n",
       "cc.Age                          float64\n",
       "cc.Sex                            int64\n",
       "cc.BlackDum                       int64\n",
       "cc.WhiteDum                       int64\n",
       "cc.maxeduc.4yr                    int64\n",
       "cc.maxeduc.hs                     int64\n",
       "cc.isimmigrant                    int64\n",
       "cc.child18                      float64\n",
       "cc.union                        float64\n",
       "cc.newsint                      float64\n",
       "cc.Ideo7                        float64\n",
       "cc.EvanProt                     float64\n",
       "cc.Catholic                     float64\n",
       "cc.Religiosity                  float64\n",
       "demo.popdense                   float64\n",
       "cc.RepDum                       float64\n",
       "cc.IndDum                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftmp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "- for each column \n",
    "    - get type \n",
    "    - for categorical variable (int32) increment to next int.\n",
    "    - for float 64, continuous var, increment by 1. (each float64 column has already been divided by standard deviation.So its std-deviation is 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for column cc.emp.nojob the results are [(0, array([0.])), (1, array([0.]))]\n",
      " PROBLEM, STDDEV EXCEEDS MAX VAL, 1.9396806189703275 > 1.5799542961462802\n",
      "for column cc.CC16_304 the results are [(0.9396806189703275, array([0.])), (1.9396806189703275, array([0.]))]\n",
      "for column cc.faminc the results are [(0.9330832316116301, array([0.])), (1.9330832316116302, array([0.]))]\n",
      "for column crashpc the results are [(0.8587735892548911, array([0.])), (1.8587735892548911, array([0.]))]\n",
      "for column rustpc the results are [(0.7205782078407131, array([0.])), (1.7205782078407132, array([0.]))]\n",
      "for column job.uer the results are [(0.9613650191084155, array([0.])), (1.9613650191084155, array([0.]))]\n",
      "for column econ.mhi the results are [(0.9709426336017595, array([0.])), (1.9709426336017595, array([0.]))]\n",
      "for column econ.hhpov.p the results are [(0.9132809117572355, array([0.])), (1.9132809117572354, array([0.]))]\n",
      "for column taa.wrks.disc95.pcpy the results are [(0.6346131510264463, array([0.])), (1.6346131510264463, array([0.]))]\n",
      "for column cc.CC16_305_2 the results are [(0, array([0.])), (1, array([0.]))]\n",
      "for column mort.ucd.despair.disc95.pdpy the results are [(0.9634906753592076, array([0.])), (1.9634906753592076, array([0.]))]\n",
      " PROBLEM, STDDEV EXCEEDS MAX VAL, 1.8211144375890467 > 1.7011384381113797\n",
      "for column cc.immviewsum the results are [(0.8211144375890467, array([0.])), (1.8211144375890467, array([0.]))]\n",
      "for column cc.raceviewsum the results are [(0.9361119104234581, array([0.])), (1.936111910423458, array([0.]))]\n",
      " PROBLEM, STDDEV EXCEEDS MAX VAL, 1.9990904265627623 > 1.18343614785796\n",
      "for column cc.CC16_307 the results are [(0.9990904265627621, array([0.])), (1.9990904265627623, array([0.]))]\n",
      "for column cc.CC16_351B the results are [(0.5074590364392272, array([0.])), (1.0, array([0.]))]\n",
      " PROBLEM, STDDEV EXCEEDS MAX VAL, 2.034221645842143 > 1.8718035698140703\n",
      "for column cc.Age the results are [(1.0342216458421427, array([0.])), (2.034221645842143, array([0.]))]\n",
      "for column cc.Sex the results are [(1, array([0.])), (0, array([0.]))]\n",
      "for column cc.BlackDum the results are [(0, array([0.])), (1, array([0.]))]\n",
      "for column cc.WhiteDum the results are [(1, array([0.])), (0, array([0.]))]\n",
      "for column cc.maxeduc.4yr the results are [(0, array([0.])), (1, array([0.]))]\n",
      "for column cc.maxeduc.hs the results are [(0, array([0.])), (1, array([0.]))]\n",
      "for column cc.isimmigrant the results are [(0, array([0.])), (1, array([0.]))]\n",
      "for column cc.child18 the results are [(0.23171924675959893, array([0.])), (1.0, array([0.]))]\n",
      "for column cc.union the results are [(0.28241623868916604, array([0.])), (1.0, array([0.]))]\n",
      "for column cc.newsint the results are [(0.7081982224623056, array([0.])), (1.7081982224623056, array([0.]))]\n",
      " PROBLEM, STDDEV EXCEEDS MAX VAL, 1.9171022870270469 > 1.5787705997223502\n",
      "for column cc.Ideo7 the results are [(0.9171022870270469, array([0.])), (1.9171022870270469, array([0.]))]\n",
      "for column cc.EvanProt the results are [(0.2767913915382734, array([0.])), (1.0, array([0.]))]\n",
      "for column cc.Catholic the results are [(0.22325752017608216, array([0.])), (1.0, array([0.]))]\n",
      " PROBLEM, STDDEV EXCEEDS MAX VAL, 1.9199637983670417 > 1.53859991039871\n",
      "for column cc.Religiosity the results are [(0.9199637983670417, array([0.])), (1.9199637983670417, array([0.]))]\n",
      "for column demo.popdense the results are [(0.2602228693703623, array([0.])), (1.2602228693703623, array([0.]))]\n",
      "for column cc.RepDum the results are [(0.2728784543898264, array([0.])), (1.0, array([1.]))]\n",
      "for column cc.IndDum the results are [(0.2607972609439961, array([0.])), (1.0, array([0.]))]\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    print(f\"for column {col} the results are {mems.getMEM_avgplusone(m_rf, col)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "691px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "335px",
    "left": "2px",
    "right": "20px",
    "top": "400px",
    "width": "648px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
