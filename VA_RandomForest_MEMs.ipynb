{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is the Marginal Effects at Means portion of the project\n",
    "Please be sure to run DataCleaning.ipynb first to prepare the data\n",
    "\n",
    "This notebook based on Fastai V1 ML course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.tabular import *\n",
    "from fastai import *\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 60\n",
    "pd.options.display.max_rows = 60\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# Visualizations\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETERMINE IF YOU ARE USING RAW OR SCALED\n",
    "Scaled is Zhao's data, continuous variables divided by standard deviation\n",
    "<br>Raw is unscaled raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "useSavedModel=True\n",
    "filename_model_params = \"RF_model_params.sav\"\n",
    "useRaw=False\n",
    "outdir = 'outBElectionResultsScaled2'\n",
    "filename='results.csv'\n",
    "filename_all = 'results_complete.csv'\n",
    "filename_model_params = \"RF_model_params.sav\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# the dependant variable(s)\n",
    "columns_dep_var= ['cc.TrumpGEVote','cc.TrumpPVote', 'cc.vote12.gop']\n",
    "\n",
    "#get the data\n",
    "if (useRaw == True):\n",
    "    df = pd.read_csv('./data/ccesplus.csv',encoding = \"ISO-8859-1\")\n",
    "else:\n",
    "    df = pd.read_csv('./data/ccesplus_fscaled.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the columns of interest, including all dependent vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.read_excel('./data/CCESplusVariables.xlsx',encoding = \"ISO-8859-1\")\n",
    "\n",
    "# for every regid=3.1 get the third column (variable name) convert to a list\n",
    "columns = list(all[ (all['regid']==1.1) & (all['exclude']!='t')  ].iloc[:,2])\n",
    "\n",
    "# #strip dependant variables\n",
    "# columns = [col for col in columns if col not in columns_dep_var]\n",
    "# columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING! 'cc.i.white.educhs not in df! No worries though \n",
    "#its correlated with composed of cc.maxeduc.hs and cc.WhiteDum\n",
    "#so drop it\n",
    "columns.remove('cc.i.white.educhs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract just those columns from orig dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which dependant variable to operate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = columns_dep_var[0]\n",
    "dump_these_dep_var_columns=columns_dep_var.copy()\n",
    "dump_these_dep_var_columns.remove(dep_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN dependent variable rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 23710 rows where cc.TrumpGEVote=NaN\n"
     ]
    }
   ],
   "source": [
    "def remove_dep_var_nan_rows(df, col_dep_var, dump_these_dep_var_columns ,silent = False):\n",
    "    \"\"\"\n",
    "    parse df into rows where df.col_dep_var does not have NaNs, \n",
    "    df: dataframe to pull NaN rows out of\n",
    "    col_dep_var: dependent variable\n",
    "    dump_these_dep_var_columns: other dep_var columns that may be highly correlated with dep var\n",
    "    \"\"\"\n",
    "    dftmp= df.copy()\n",
    "    \n",
    "    if(silent is False):\n",
    "        print(f'dropping {(pd.isnull(dftmp[col_dep_var])).sum()} rows where {col_dep_var}=NaN')\n",
    "                      \n",
    "    #dump the NaN rows\n",
    "    dftmp = dftmp[pd.notnull(dftmp[col_dep_var] )]\n",
    "    \n",
    "    #dump the dump_these_dep_var_columns\n",
    "    dftmp.drop(dump_these_dep_var_columns,axis=1,inplace=True);\n",
    "    \n",
    "    return dftmp\n",
    "\n",
    "# pull out the nulls from the column of interest\n",
    "dftmp= remove_dep_var_nan_rows(df, columns_dep_var[0],dump_these_dep_var_columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out categorical and continuous variables\n",
    "see if fastai can auto do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #give fastai a shot at splitting cat and cont variables\n",
    "res_cont, res_cat = cont_cat_split(dftmp,max_card=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorify and Fill Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from docs https://docs.fast.ai/tabular.transform.html\n",
    "tfm = Categorify(cat_names=res_cat, cont_names=res_cont)\n",
    "tfm(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm1 = FillMissing(cat_names=res_cat, cont_names=res_cont)\n",
    "tfm1(dftmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36801\n",
      "4089\n"
     ]
    }
   ],
   "source": [
    "# split out train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trn=tst=None\n",
    "trn,tst = train_test_split(dftmp, test_size=0.1)\n",
    "print(str(len(trn)))\n",
    "print(str(len(tst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split out trn_y and tst_y\n",
    "#this is the dep_var, converted to an int\n",
    "trn_y = trn[dep_var].copy()\n",
    "tst_y = tst[dep_var].copy()\n",
    "trn_y.astype('int64');\n",
    "trn_y.astype('int64');\n",
    "\n",
    "trn.drop(dep_var,axis=1,inplace=True);\n",
    "tst.drop(dep_var,axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a RandomForest on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "if (useSavedModel):\n",
    "    # load the model from disk\n",
    "    m_rf = pickle.load(open(outdir+\"/\"+filename_model_params, 'rb'))\n",
    "else:\n",
    "    #create a random forest object\n",
    "    m_rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, oob_score=True, max_features='auto', min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmse(x,y): \n",
    "    '''this and R**2 used for continuous variables'''\n",
    "    return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m, trn, trn_y, tst, tst_y):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    res = [m.score(trn, trn_y), m.score(tst, tst_y)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)\n",
    "\n",
    "def eval_accuracy(preds,targs, silent=True):\n",
    "    totals = len(preds)\n",
    "    matches = 0\n",
    "    for x in zip(preds,targs):\n",
    "        if x[0]==x[1]:\n",
    "            matches+=1\n",
    "    acc=100*matches/totals \n",
    "    if( silent == False):\n",
    "        print(f\"Got {matches} right out of {totals} samples, Accuracy is {acc} percent\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=999, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9385614521344529, 0.9151381755930545, 0.9162794489280183]\n"
     ]
    }
   ],
   "source": [
    "#train the random forest \n",
    "m_rf.fit(trn, trn_y)\n",
    "print_score(m_rf, trn, trn_y, tst, tst_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just another way to see stuff\n",
    "# preds1 = m_rf.predict(tst)\n",
    "# eval_accuracy(preds1,tst_y,silent=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run MEMs on columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this directory contains symlink created at command line like this\n",
    "# ln -s ../Marginal_Effects_at_Means ./Marginal_Effects_at_Means\n",
    "#it allows this directory to find Marginal_Effects_at_Means, a directory 1 above this one\n",
    "#this dir contains a file called mem.py which contains MEMs\n",
    "from Marginal_Effects_at_Means.mem import MEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ON WHOLE DATASET OR JUST THE TestSET?  I'm thinking the whole dataset.  \n",
    "# The model has some idea of how voters will vote based on the input features, lets use that knowledge\n",
    "#to see what happens when we start changing variables\n",
    "mems = MEMs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: For categorical variables, increment to next int, For continuous vars, get the standard deviations of each column of interest.  increment =std/1000.  See paper "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "691px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "467px",
    "left": "2px",
    "right": "20px",
    "top": "400px",
    "width": "690px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
